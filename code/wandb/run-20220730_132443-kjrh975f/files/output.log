Completed till split
Data Encoding is Completed...
Epoch 1/20
2022-07-30 13:24:46.132000: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory
2022-07-30 13:24:46.132025: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)
2022-07-30 13:24:46.132041: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (akshat): /proc/driver/nvidia/version does not exist
2022-07-30 13:24:46.136499: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
[34m[1mwandb[39m[22m: [33mWARNING[39m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.
2022-07-30 13:24:46.822430: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0
2022-07-30 13:24:46.823226: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session
WARNING:tensorflow:From /home/akshat/Documents/Github/ner_env/lib/python3.10/site-packages/tensorflow/python/ops/math_ops.py:3836: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`








118/118 [==============================] - 22s 158ms/step - loss: 0.1312 - accuracy: 0.9783 - val_loss: 0.0625 - val_accuracy: 0.9837 - _timestamp: 1659180309.0000 - _runtime: 26.0000
Epoch 2/20









118/118 [==============================] - 20s 170ms/step - loss: 0.0485 - accuracy: 0.9856 - val_loss: 0.0451 - val_accuracy: 0.9853 - _timestamp: 1659180329.0000 - _runtime: 46.0000
Epoch 3/20










118/118 [==============================] - 21s 179ms/step - loss: 0.0299 - accuracy: 0.9892 - val_loss: 0.0326 - val_accuracy: 0.9893 - _timestamp: 1659180350.0000 - _runtime: 67.0000
Epoch 4/20









118/118 [==============================] - 21s 178ms/step - loss: 0.0199 - accuracy: 0.9928 - val_loss: 0.0287 - val_accuracy: 0.9908 - _timestamp: 1659180371.0000 - _runtime: 88.0000
Epoch 5/20










118/118 [==============================] - 21s 178ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 0.0265 - val_accuracy: 0.9920 - _timestamp: 1659180392.0000 - _runtime: 109.0000
Epoch 6/20









118/118 [==============================] - 21s 178ms/step - loss: 0.0116 - accuracy: 0.9963 - val_loss: 0.0270 - val_accuracy: 0.9924 - _timestamp: 1659180413.0000 - _runtime: 130.0000
Epoch 7/20










118/118 [==============================] - 21s 181ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.0264 - val_accuracy: 0.9928 - _timestamp: 1659180435.0000 - _runtime: 152.0000
Epoch 8/20









118/118 [==============================] - 21s 179ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 0.0263 - val_accuracy: 0.9931 - _timestamp: 1659180456.0000 - _runtime: 173.0000
Epoch 9/20









118/118 [==============================] - 21s 182ms/step - loss: 0.0067 - accuracy: 0.9979 - val_loss: 0.0270 - val_accuracy: 0.9931 - _timestamp: 1659180478.0000 - _runtime: 195.0000
Epoch 10/20










118/118 [==============================] - 21s 180ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.0289 - val_accuracy: 0.9930 - _timestamp: 1659180499.0000 - _runtime: 216.0000
Epoch 11/20










118/118 [==============================] - 21s 180ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 0.0337 - val_accuracy: 0.9925 - _timestamp: 1659180520.0000 - _runtime: 237.0000
Epoch 12/20









118/118 [==============================] - 22s 182ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0289 - val_accuracy: 0.9930 - _timestamp: 1659180542.0000 - _runtime: 259.0000
Epoch 13/20











118/118 [==============================] - 24s 204ms/step - loss: 0.0040 - accuracy: 0.9987 - val_loss: 0.0299 - val_accuracy: 0.9931 - _timestamp: 1659180566.0000 - _runtime: 283.0000
Epoch 14/20















118/118 [==============================] - 31s 264ms/step - loss: 0.0034 - accuracy: 0.9989 - val_loss: 0.0309 - val_accuracy: 0.9929 - _timestamp: 1659180597.0000 - _runtime: 314.0000
Epoch 15/20












118/118 [==============================] - 27s 225ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0347 - val_accuracy: 0.9928 - _timestamp: 1659180624.0000 - _runtime: 341.0000
Epoch 16/20













118/118 [==============================] - 28s 233ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0328 - val_accuracy: 0.9925 - _timestamp: 1659180651.0000 - _runtime: 368.0000
Epoch 17/20










118/118 [==============================] - 23s 191ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0332 - val_accuracy: 0.9926 - _timestamp: 1659180674.0000 - _runtime: 391.0000
Epoch 18/20











118/118 [==============================] - 23s 194ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 0.0339 - val_accuracy: 0.9928 - _timestamp: 1659180697.0000 - _runtime: 414.0000
Epoch 19/20













118/118 [==============================] - 29s 244ms/step - loss: 0.0021 - accuracy: 0.9994 - val_loss: 0.0343 - val_accuracy: 0.9928 - _timestamp: 1659180726.0000 - _runtime: 443.0000
Epoch 20/20













118/118 [==============================] - 27s 228ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0365 - val_accuracy: 0.9921 - _timestamp: 1659180753.0000 - _runtime: 470.0000
Model saved in model directory...
Trainign NN is completed...
Curves Plotted and Stored in the Directory...